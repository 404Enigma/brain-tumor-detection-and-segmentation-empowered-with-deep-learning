{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries & Cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import torch,torchvision\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "from monai.data import Dataset, ArrayDataset, create_test_image_3d, DataLoader\n",
    "from monai.data import CacheDataset\n",
    "from torch.utils.data import random_split\n",
    "import torchvision.transforms as transform\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = torch.load('Data/UpdatedFullDataV_2_0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val = int((len(train_data)/100)*20) # 30%\n",
    "org = len(train_data)-val\n",
    "print(val,org)\n",
    "train_ds,val_ds = random_split(train_data,[org,val])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 5\n",
    "train_loder = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "val_loder = DataLoader(val_ds, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "%autoreload 2\n",
    "import Models.pix2pix as Model\n",
    "PRINTLOG_G = False\n",
    "PRINTLOG_D = True\n",
    "PRINTLOG = False\n",
    "print(Model.Logs(PRINTLOG))\n",
    "print(Model.G_Logs(PRINTLOG_G))\n",
    "print(Model.D_Logs(PRINTLOG_D))\n",
    "model = Model.Pix2Pix(1,1,device, save_after= 5)\n",
    "model.train(train_loder,val_loder,1)\n",
    "PRINTLOG = False\n",
    "print(Model.Logs(PRINTLOG))\n",
    "print(Model.G_Logs(PRINTLOG))\n",
    "print(Model.D_Logs(PRINTLOG))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show(img,output,label,denorm = False):\n",
    "    img,output,label = img.cpu(),output.cpu(),label.cpu()\n",
    "    if(len(output) != 1):\n",
    "      fig,ax = plt.subplots(len(output),3,figsize=(15,15))\n",
    "    else:\n",
    "      fig,ax = plt.subplots(len(output),3,figsize=(30,10))\n",
    "    cols = ['Input Image','Actual Output','Predicted Output']\n",
    "    for i in range(len(output)):\n",
    "        if(len(output) != 1):\n",
    "          Img,Lab,act = img[i],output[i],label[i]\n",
    "          Img,Lab,act = Img.detach().numpy()[0,:,:],Lab.detach().numpy()[0,:,:],act.detach().numpy()[0,:,:]\n",
    "          ax[i][0].imshow(Img,cmap='gray')\n",
    "          ax[i][2].imshow(Lab,cmap='gray')\n",
    "          ax[i][1].imshow(act,cmap='gray')\n",
    "        else:\n",
    "          Img,Lab,act = img[i],output[i],label[i]\n",
    "          Img,Lab,act = Img.detach().numpy()[0,:,:],Lab.detach().numpy()[0,:,:],act.detach().numpy()[0,:,:]\n",
    "          ax[0].imshow(Img,cmap='gray')\n",
    "          ax[2].imshow(Lab,cmap='gray')\n",
    "          ax[1].imshow(act,cmap='gray')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lr(optimizer):\n",
    "  for param_group in optimizer.param_groups:\n",
    "      return param_group['lr']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameteric Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = UNet(1).float().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.0001\n",
    "lossfunc = nn.L1Loss()\n",
    "LOSS_FUNC = 'L1LOSS'\n",
    "\n",
    "optimizer = torch.optim.RAdam(model.parameters(), lr=lr)\n",
    "OPTIM = 'RAdam'\n",
    "\n",
    "scheduler = None#torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience = 5, factor = 0.9)\n",
    "SCHEDULER = None#'RedOnPlatu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VERSION = 1\n",
    "DATA = 'UpdatedFullData_V_2'\n",
    "log_dir = 'logs'\n",
    "\n",
    "METHOD = f'{DATA}_Lr{lr}_optim{OPTIM}_loss{LOSS_FUNC}_schedular{SCHEDULER}_epoch{epochs}_ver{VERSION}_randtest'\n",
    "path = f'{log_dir}/{METHOD}'\n",
    "path2 = path + '_validation'\n",
    "METHOD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf /logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writter_train = SummaryWriter(path)\n",
    "writter_validate = SummaryWriter(path2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Traning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_acc = []\n",
    "val_acc = []\n",
    "train_loss = []\n",
    "val_loss = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_count = 0\n",
    "valid_count = 0\n",
    "train_count_epi = 0\n",
    "valid_count_epi = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(epochs):\n",
    "    # if i<300:\n",
    "    #   clear_output()\n",
    "    trainloss = 0\n",
    "    valloss = 0\n",
    "    \n",
    "    train_loss_log = 0\n",
    "    c = 0\n",
    "    for d in tqdm(train_loder):\n",
    "        '''\n",
    "            Traning the Model.\n",
    "        '''\n",
    "        optimizer.zero_grad()\n",
    "        img = d['MR']\n",
    "        label = d['CT']\n",
    "        \n",
    "        img = img.to(device).float()\n",
    "        label = label.to(device).float()\n",
    "        output = model(img)\n",
    "        loss = lossfunc(output,label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        trainloss += loss.item()\n",
    "        writter_train.add_scalar('Loss/Per Step Loss',loss.item(),train_count)\n",
    "        writter_train.add_scalar('Learning Rate/Per Step LR',get_lr(optimizer),train_count)\n",
    "        \n",
    "        train_count+=1\n",
    "    \n",
    "\n",
    "    if i==0:\n",
    "      prev_loss = trainloss/len(train_loder)\n",
    "    else:\n",
    "      diff_in_loss = abs(trainloss/len(train_loder) - prev_loss ) \n",
    "      prev_loss = trainloss/len(train_loder)\n",
    "      writter_train.add_scalar('Loss/Rate of change',diff_in_loss,train_count_epi)\n",
    "\n",
    "    train_loss.append(trainloss/len(train_loder))  \n",
    "    writter_train.add_scalar('Loss/Avg Loss',trainloss/len(train_loder),train_count_epi)  \n",
    "    writter_train.add_scalar('Learning Rate/Per Batch LR',get_lr(optimizer),train_count_epi)\n",
    "    train_count_epi += 1\n",
    "\n",
    "    for d in tqdm(val_loder):\n",
    "        '''\n",
    "            Validation of Model.\n",
    "        '''\n",
    "        img = d['MR']\n",
    "        label = d['CT']\n",
    "        img = img.to(device).float()\n",
    "        label = label.to(device).float()\n",
    "        output = model(img)\n",
    "        loss = lossfunc(output,label)\n",
    "        valloss += loss.item()\n",
    "        writter_validate.add_scalar('Loss/Per Step Loss',loss.item(),valid_count)\n",
    "        valid_count+=1\n",
    "    \n",
    "    if SCHEDULER:\n",
    "      scheduler.step(valloss/len(val_loder))\n",
    "    \n",
    "    if i%20 == 0:\n",
    "      show(img,output,label)\n",
    "    val_loss.append(valloss/len(val_loder))  \n",
    "\n",
    "    writter_validate.add_scalar('Loss/Avg Loss',valloss/len(val_loder),valid_count_epi)  \n",
    "    valid_count_epi += 1\n",
    "\n",
    "    writter_validate.add_scalar('Loss/Diff in Loss',(valloss/len(val_loder) - trainloss/len(train_loder)) ,valid_count_epi)  \n",
    "    img_grid = torchvision.utils.make_grid(output)\n",
    "    writter_validate.add_image('Images/Validation',img_grid,valid_count_epi)  \n",
    "    \n",
    "    print(\"epoch : {} ,train loss : {:.6f} ,valid loss : {:.6f} \".format(i,train_loss[-1],val_loss[-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cuda Clear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if device == 'cuda':\n",
    "    torch.cuda.empty_cache()\n",
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del train_loder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if device == 'cuda':\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "70b7d423b81800acba78e7d290e9b857a2fca8627332521ec6be74c34aca145f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
